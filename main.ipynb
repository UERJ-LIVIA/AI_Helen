{"cells":[{"cell_type":"code","execution_count":48,"metadata":{"id":"EoU4LWt-NwBJ"},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import StepLR\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda, Compose\n","from sklearn.preprocessing import StandardScaler #divisão de dados e pré-processamento\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import pathlib\n","import pysr\n","pysr.silence_julia_warning()\n","import json\n","import os\n","import dill as pickle\n","import time\n","\n"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"pwDP1PrFNwBb","outputId":"6fe3e93c-1054-405a-d643-463763c70748"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"nAOFruYQNwBg"},"outputs":[],"source":["class MyDataset():\n"," \n","  def __init__(self, data):\n","\n","    data = data.values\n"," \n","    x = data[:, 0:-1]\n","    sc = StandardScaler() #dimensionamos nosso conjunto de dados #mesma ordem ñ precisa\n","    x_sc = sc.fit_transform(x)\n","    \n","    y = data[:, -1]\n"," \n","    self.x_train=torch.tensor(x_sc, dtype=torch.float32) #convertendo nosso conjunto de dados em tensores de tocha.\n","    #self.x_train=torch.tensor(x, dtype=torch.float32)\n","    self.x_train = self.x_train.to(device)\n","    \n","    self.y_train=torch.tensor(y, dtype=torch.float32)\n","    self.y_train = self.y_train.to(device)\n","    \n"," \n","  def __len__(self):\n","    return len(self.y_train)\n","   \n","  def __getitem__(self,idx):\n","    return self.x_train[idx],  torch.unsqueeze(self.y_train[idx], dim=0) #Retorna um novo tensor com uma dimensão de tamanho um inserido na posição especificada.\n","\n","    #funcionalidade literal de obter um único ponto de dados por índice e retornar o comprimento do conjunto de dados.\n","\n"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"Ig4nvsHkNwBj"},"outputs":[],"source":["def read_data(data_path, sep=','):\n","    print(\"Loading the data ...\")\n","    file_extension = pathlib.Path(data_path).suffix\n","\n","    if file_extension == '.txt':\n","        data = np.loadtxt(data_path)\n","        assert isinstance(data, np.ndarray), f\"The input file must be a numpy array but is {type(data)}\"\n","        col_names = ['X'+str(i+1) for i in range(data.shape[1])]\n","        data = pd.DataFrame(data, columns=col_names, dtype=np.float32)\n","    elif file_extension == '.csv':\n","        data = pd.read_csv(data_path, sep=sep, dtype=np.float32)\n","    else:\n","        print(f\"the type of the data is {type(file_extension)} but a csv or saved numpy array is expected\")\n","        raise TypeError()\n","    print(\"Reading the data is done!\")\n","    return data"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"Tm2yT0nLNwBl","outputId":"4b5304fe-1b7f-4186-9cd6-7855ad594259"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading the data ...\n","Reading the data is done!\n"]}],"source":["data = read_data('example2.txt')"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"4AYRVUwZNwBm"},"outputs":[],"source":["myDs=MyDataset(data)\n","train_loader=DataLoader(myDs, batch_size=2048, shuffle=True)"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"YCLAHPy5NwBn"},"outputs":[],"source":["def network(input_dimension,hidden_dimension, output_dimension):\n","\n","  print(\"Constructing the neural network...\")\n","\n","  modules=[]\n","  modules.append(torch.nn.Linear(input_dimension, hidden_dimension[0]))\n","  modules.append(torch.nn.ReLU()) #função de ativação\n","  for i in range(len(hidden_dimension)-1):\n","    modules.append(torch.nn.Linear(hidden_dimension[i], hidden_dimension[i+1]))\n","    modules.append(torch.nn.ReLU())\n","\n","  modules.append(torch.nn.Linear(hidden_dimension[-1], output_dimension))\n","\n","  net = torch.nn.Sequential(*modules) #incializar módulo interno\n","\n","  if torch.cuda.is_available():\n","    net = net.to(device)\n","  \n","  print(\"Construction is done!\")\n","  \n","  return net\n"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"-gbRjwZVNwBp","outputId":"948cce6b-7ad1-4f80-db57-5e226640f9cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Constructing the neural network...\n","Construction is done!\n"]}],"source":["dim_features = data.shape[1] - 1\n","net= network(dim_features, [200,200,200, 100, 100], 1)"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"gr6EFBqvNwBs"},"outputs":[],"source":["def train(net, train_loader, epochs=100, verbose=1):\n","\n","  print(\"Training the neural network with the data...\")\n","  n_show_epoch = int(epochs/10)\n","\n","  loss_func = nn.MSELoss()\n","\n","\n","  optimizer = torch.optim.Adam(net.parameters()) #Gradient Descent\n","  scheduler = StepLR(optimizer, step_size=int(epochs/10), gamma=0.1, verbose=False)\n","\n","\n","  for e in range(epochs):\n","  \n","    running_loss= 0\n","\n","    for features,labels in train_loader:\n","        \n","        output= net(features) \n","\n","        loss= loss_func(output, labels)\n","        optimizer.zero_grad() #zerar gradientens - não se quer acumulação\n","        loss.backward() #cálculo do gradiente de perda\n","        \n","        optimizer.step() #atualiza os parâmentros\n","        scheduler.step()\n","        \n","\n","        running_loss += loss.item ()\n","    if verbose and e % n_show_epoch==0:\n","      print(f\"epoch: {e}/{epochs}, loss: {loss.item()}\")\n","\n","  print(f\"Training the neural network is done! The final loss is {loss.item()}\")  \n","  \n","  return net\n"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"B4l7fJKBNwBu"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the neural network with the data...\n","epoch: 0/2000, loss: 39.24441146850586\n","epoch: 200/2000, loss: 10.462998390197754\n","epoch: 400/2000, loss: 4.621273517608643\n","epoch: 600/2000, loss: 5.732011318206787\n","epoch: 800/2000, loss: 9.236776351928711\n","epoch: 1000/2000, loss: 6.360742092132568\n","epoch: 1200/2000, loss: 7.206399440765381\n","epoch: 1400/2000, loss: 7.268052101135254\n","epoch: 1600/2000, loss: 5.322818279266357\n","epoch: 1800/2000, loss: 5.892086505889893\n","Training the neural network is done! The final loss is 3.627647876739502\n"]}],"source":["model = train(net, train_loader, epochs=2000, verbose=1)"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"0J96IaNoNwBv"},"outputs":[],"source":["def check_translational_symmetry_plus(model, data, min_error=0.05, shift=None, verbose=1):\n","\n","    print(\"Checking the translational symmetry by plus...\")\n","    data_translated = torch.from_numpy(data.values).to(device)\n","    #print(data_translated[:5, :])\n","    num_variables = data_translated.size()[1] - 1\n","    y = torch.unsqueeze(data_translated[:, -1], dim=1)\n","\n","    if os.path.exists('columns.pkl'):\n","        columns = pickle.load(\"columns.pkl\")\n","    else:\n","        columns = []\n","        \n","\n","\n","    with torch.no_grad():            \n","        \n","        for i in range(num_variables):\n","            for j in range(i+1, num_variables):\n","                #if i<j:\n","                x = data_translated[:, 0:-1].clone()\n","                #print(data_translated[:5, :])\n","\n","\n","                if shift is None:\n","                    shift = 0.5 * min(torch.std(x[:,i]),torch.std(x[:,j]))\n","\n","                x[:,i] += shift #(x[:,i] + shift).clone()\n","                x[:,j] += shift #(x[:,j] + shift).clone()\n","                errors = abs(y - model(x))\n","                error = torch.median(errors)\n","                if verbose:\n","                    print(f\"Columns {(i+1,j+1)} -> error {error}\")\n","                if error < min_error:\n","                    #columns[(i+1,j+1)] = float(error)\n","                    columns.append([i+1, j+1])\n","    with open('columns.pkl', 'wb') as f:\n","        pickle.dump(columns, 'columns.pkl')\n","        \n","    print(\"Checking the translational symmetry is done!\")\n","    \n","    #return columns"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"lU2jwfhdNwBw"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking the translational symmetry by plus...\n","Columns (1, 2) -> error 0.007878899574279785\n","Columns (1, 3) -> error 0.5623359680175781\n","Columns (1, 4) -> error 0.5594482421875\n","Columns (2, 3) -> error 0.562767505645752\n","Columns (2, 4) -> error 0.5608224868774414\n","Columns (3, 4) -> error 0.00790262222290039\n","Checking the translational symmetry is done!\n"]}],"source":["columns = check_translational_symmetry_plus(model, data, min_error=0.05)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def check_translational_symmetry_didive(model, data, min_error=0.05, shift=None, verbose=1):\n","\n","    print(\"Checking the translational symmetry by divide...\")\n","    data_translated = torch.from_numpy(data.values).to(device)\n","    #print(data_translated[:5, :])\n","    num_variables = data_translated.size()[1] - 1\n","    y = torch.unsqueeze(data_translated[:, -1], dim=1)\n","\n","    if os.path.exists('columns.pkl'):\n","        columns = pickle.load(\"columns.pkl\")\n","    else:\n","        columns = []\n","        \n","\n","\n","    with torch.no_grad():            \n","        \n","        for i in range(num_variables):\n","            for j in range(i+1, num_variables):\n","                #if i<j:\n","                x = data_translated[:, 0:-1].clone()\n","                #print(data_translated[:5, :])\n","\n","\n","                if shift is None:\n","                    shift = 0.5 * min(torch.std(x[:,i]),torch.std(x[:,j]))\n","\n","                x[:,i] /= shift #(x[:,i] + shift).clone()\n","                x[:,j] /= shift #(x[:,j] + shift).clone()\n","                errors = abs(y - model(x))\n","                error = torch.median(errors)\n","                if verbose:\n","                    print(f\"Columns {(i+1,j+1)} -> error {error}\")\n","                if error < min_error:\n","                    #columns[(i+1,j+1)] = float(error)\n","                    columns.append([i+1, j+1])\n","    with open('columns.pkl', 'wb') as f:\n","        pickle.dump(columns, 'columns.pkl')\n","        \n","    print(\"Checking the translational symmetry is done!\")\n","    \n","    #return columns"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"OSPt8vM5NwBx"},"outputs":[],"source":["def save_dict(dict_path, obj):\n","    with open(dict_path, 'w') as convert_file:\n","        convert_file.write(json.dumps(obj))\n","\n","def read_dict(dict_path):\n","    with open(dict_path) as json_file:\n","        d = json.load(json_file)\n","    return d"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["'X4'"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["data_new = data.iloc[:, 0:-1].copy()\n","data_new.columns[-1]"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"L9HGFgCqNwBy"},"outputs":[],"source":["def apply_translational_symmetry(data, columns):\n","    print(f\"Reducing the number of indepent variables by {len(columns)}\")\n","\n","\n","    if os.path.exists('variable_change.json'):\n","        variable_change = read_dict('variable_change.json')\n","    else:\n","        variable_change = dict()\n","\n","    data_new = data.iloc[:, 0:-1].copy()\n","    for i, j in columns:\n","        \n","        if data_new.columns[-1][0] == 'X':\n","            col_num = 1\n","        else:\n","            col_num = int(data_new.columns[-1][1:]) + 1\n","        data_new['u'+str(col_num)] = data_new.iloc[:, i-1] - data_new.iloc[:, j-1]\n","        variable_change['u'+str(col_num)] = data_new.columns[i-1] + '-' + data_new.columns[j-1]\n","\n","\n","\n","    #drop_cols = list(set([i for l in columns.keys() for i in l])) # the list of the columns to be deleted\n","    #drop_cols = [i-1 for i in drop_cols] #correcting the index of the columns to be deleted\n","    drop_cols = [i-1 for sublist in columns for i in sublist]\n","\n","    data_new = data_new.drop(labels=data.columns[drop_cols], axis=1)\n","    data_new = pd.concat([data_new, data.iloc[:, -1]], axis=1)\n","    \n","    data_new.to_csv('data_new.csv', index=False)\n","    save_dict('variable_change.json', variable_change)\n","\n","    return data_new, variable_change\n","  "]},{"cell_type":"code","execution_count":68,"metadata":{"id":"Dz3odfTvNwBz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reducing the number of indepent variables by 2\n"]}],"source":["data_new, variable_change = apply_translational_symmetry(data, columns)"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"npgUFhV0NwB0"},"outputs":[],"source":["def SR_GA(path_data, number_of_samples=500, iterations=10):\n","    data = pd.read_csv(path_data)\n","    indices = np.random.choice(data.shape[0], number_of_samples, replace=False)\n","    X = data.iloc[indices, 0:-1]  #separando variáveis de entrada\n","    y = data.iloc[indices, -1].values\n","\n","    sr_model = pysr.PySRRegressor(\n","    niterations=iterations,\n","    #populations=10,\n","    binary_operators=[\"+\", \"*\", \"-\", \"/\", \"pow\"],\n","    #batching=True,\n","    #batchSize = 128,\n","    #procs = 20,\n","    #multithreading = True,\n","    unary_operators=[\n","        \"cos\",\n","        \"exp\",\n","        \"sin\",  # Pre-defined library of operators (see docs)\n","        \"inv(x) = 1/x\",  # Define your own operator! (Julia syntax)\n","                    ],\n","    model_selection=\"best\",\n","    loss=\"loss(x, y) = (x - y)^2\",  # Custom loss function (julia syntax)\n","    )\n","\n","    sr_model.fit(X, y)\n","\n"," \n","    sr_model.equations.to_csv('results.csv', index=False)\n","    #sr_model.raw_julia_state = None\n","\n","    #with open('sr_model.pkl', 'wb') as sr_model_file:\n","    #    pickle.dump(sr_model, sr_model_file)\n","\n","\n","\n","    return sr_model\n","\n"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"m58Nv_z9NwB0","outputId":"7c36e776-433b-443b-eec5-78a2cbe13f11"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/vahid/miniconda3/lib/python3.9/site-packages/pysr/sr.py:942: UserWarning: Resetting variable_names from X.columns\n","  warnings.warn(\"Resetting variable_names from X.columns\")\n","  Activating project at `~/.julia/environments/pysr-0.7.9`\n","    Updating registry at `~/.julia/registries/General.toml`\n","   Resolving package versions...\n","  No Changes to `~/.julia/environments/pysr-0.7.9/Project.toml`\n","  No Changes to `~/.julia/environments/pysr-0.7.9/Manifest.toml`\n","  No Changes to `~/.julia/environments/pysr-0.7.9/Project.toml`\n","  No Changes to `~/.julia/environments/pysr-0.7.9/Manifest.toml`\n"]}],"source":["sr_model = SR_GA('data_new.csv', iterations=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lwwZEhMNwB1"},"outputs":[],"source":["def show_results(sr_model=None, all_results=False):\n","    \"\"\"shows the result of symbolic regression using the PySR\n","\n","    Args:\n","        sr_model (PySR model, optional): a fitted PySR model on data. Defaults to None.\n","        best (bool, optional): True means printing the best model. False means printing all the models. Defaults to True.\n","    \"\"\"\n","\n","    time.sleep(2)\n","    \n","    variable_change = read_dict('variable_change.json')\n","    # the below part for loading isn't working right now\n","    if sr_model is None:\n","        with open('sr_model.pk', 'rb') as sr_model_file:\n","            sr_model = pickle.load(sr_model_file)\n","\n","    if all_results is False:\n","        eq = sr_model.sympy()\n","        eq = eq.subs(variable_change).simplify()\n","        print(\"--------------------------\\n\")\n","        print(\"The Final Result is:\\n\")\n","        print(eq)\n","        #return eq\n","    else:\n","        print(\"--------------------------\\n\")\n","        print(\"The Final Result is:\\n\")\n","        print(sr_model.equations.replace(variable_change, regex=True).loc[:, ['loss', 'equation']])\n","        #return sr_model.equations.replace(variable_change, regex=True).loc[:, ['loss', 'equation']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOPX8wYgNwB1","outputId":"be778c6e-25c9-4eb2-d6a5-3079febadfb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(Abs(x1 - x2)**1.9997796 + Abs(x3 - x4)**1.9997953)**0.5000427\n"]}],"source":["show_results(sr_model, best=True)"]},{"cell_type":"markdown","metadata":{"id":"auH9eBY2NwB2"},"source":["Essa função abaixo junta todas as funções e executa todas para chegar na resposta final"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9WU5yOqdNwB5"},"outputs":[],"source":["def run_regression(data_path, \n","                    epochs=100,\n","                    iterations=10,\n","                    hidden_layers = [200, 200, 100],\n","                    all_results=False,\n","                    min_error=0.01,\n","                    number_of_samples=500,\n","                    batch_size = 1028,\n","                    verbose=1 ):\n","    \"\"\"run a neural_genetic symbolic regression on data\n","\n","    Args:\n","        data_path (_type_): _description_\n","        epochs (int, optional): _description_. Defaults to 100.\n","        iterations (int, optional): _description_. Defaults to 10.\n","        hidden_layers (list, optional): _description_. Defaults to [200, 200, 100].\n","        best_result (bool, optional): _description_. Defaults to True.\n","        min_error (float, optional): _description_. Defaults to 0.05.\n","        number_of_samples (int, optional): _description_. Defaults to 500.\n","        batch_size (int, optional): _description_. Defaults to 1028.\n","\n","    Returns:\n","        _type_: A fitted model of PySR type\n","    \"\"\"\n","                    \n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n","    data = read_data(data_path)\n","    myDs=MyDataset(data)\n","    train_loader=DataLoader(myDs, batch_size=batch_size, shuffle=True)\n","    dim_features = data.shape[1] - 1\n","    net= network(dim_features, hidden_layers, 1)\n","    model = train(net, train_loader, epochs=epochs, verbose=verbose)\n","    columns = check_translational_symmetry_minus(model, data, min_error=0.05, verbose=verbose)\n","    data_new, variable_change = apply_translational_symmetry(data, columns)    \n","    sr_model = SR_GA('data_new.csv', iterations=iterations, number_of_samples=number_of_samples)\n","    show_results(sr_model)\n","    \n","    return sr_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRdd1J5jNwB8"},"outputs":[],"source":["run_regression('example1.txt')"]},{"cell_type":"markdown","metadata":{"id":"d0dsbDiANwB9"},"source":["# Testar o module `sr_utils`"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Ig8PjDgINwB-"},"outputs":[],"source":["import sr_utils"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"p65Y-KzJNwB_","outputId":"a406f571-87e8-4e11-940d-f1d3cd93d3f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading the data ...\n","Reading the data is done!\n","Constructing the neural network...\n","Construction is done!\n","Training the neural network with the data...\n","epoch: 0/100, loss: 0.9433866143226624\n","epoch: 10/100, loss: 0.0052633136510849\n","epoch: 20/100, loss: 0.0009353350615128875\n","epoch: 30/100, loss: 0.0005453507765196264\n","epoch: 40/100, loss: 0.0005782583029940724\n","epoch: 50/100, loss: 0.00034297117963433266\n","epoch: 60/100, loss: 0.00026737406733445823\n","epoch: 70/100, loss: 0.0003475161793176085\n","epoch: 80/100, loss: 0.00027960652369074523\n","epoch: 90/100, loss: 0.0005731609999202192\n","Training the neural network is done! The final loss is 0.00021734654728788882\n","Checking the translational symmetry by plus...\n","Columns (1, 2) -> error 0.006580829620361328\n","Columns (1, 3) -> error 0.5619543194770813\n","Columns (1, 4) -> error 0.5637662410736084\n","Columns (2, 3) -> error 0.5615277290344238\n","Columns (2, 4) -> error 0.5633257627487183\n","Columns (3, 4) -> error 0.006571054458618164\n","Checking the translational symmetry is done!\n","Reducing the number of indepent variables by 2\n"]},{"name":"stderr","output_type":"stream","text":["/home/vahid/miniconda3/lib/python3.9/site-packages/pysr/sr.py:942: UserWarning: Resetting variable_names from X.columns\n","  warnings.warn(\"Resetting variable_names from X.columns\")\n","  Activating project at `~/.julia/environments/pysr-0.7.9`\n","    Updating registry at `~/.julia/registries/General.toml`\n","   Resolving package versions...\n","  No Changes to `~/.julia/environments/pysr-0.7.9/Project.toml`\n","  No Changes to `~/.julia/environments/pysr-0.7.9/Manifest.toml`\n","  No Changes to `~/.julia/environments/pysr-0.7.9/Project.toml`\n","  No Changes to `~/.julia/environments/pysr-0.7.9/Manifest.toml`\n"]}],"source":["model = sr_utils.run_regression('example1.txt')"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"QVm8DMPaNwB_"},"outputs":[],"source":["ll = [(1,2), (3,4)]"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/plain":["[1, 2, 3, 4]"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["[i for item in ll for i in item]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["with open(\"columns.pkl\", 'wb') as f:\n","    pickle.dump(ll, f)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["with open('columns.pkl', 'rb') as f:\n","    lll = pickle.load(f)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["[(1, 2), (3, 4)]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["lll"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"main.ipynb","provenance":[]},"interpreter":{"hash":"92b1d5f842d7c1e714e1ab666cefb8d1f75311aac337aae0336133957fcbf554"},"kernelspec":{"display_name":"Julia 1.7.1","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
